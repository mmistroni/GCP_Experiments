{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ApacheBeamNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/GCP_Experiments/blob/master/ApacheBeamNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enYLkdcol0EU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbdMCgGYOYu-",
        "colab_type": "text"
      },
      "source": [
        "<h3> Installing apache beam </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN_VLiLKOiow",
        "colab_type": "code",
        "outputId": "589afd71-e338-43e3-a185-fdc356addea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "!{'pip install --quiet apache_beam[gcp]'}\n",
        "!{'pip install --quiet google-cloud-bigquery==0.25.0'}\n",
        "#!pip uninstall -y google-cloud-dataflow\n",
        "#!pip install apache-beam[gcp] tensorflow_transform==0.8.0\n",
        "#!pip install apache-beam==2.4.0\n",
        "#!pip install google-cloud-bigquery==0.25.0\n",
        "#!pip install google-cloud-dataflow==2.4.0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.0MB 4.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 55.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 46.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 59.2MB 79kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 9.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 41.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 47.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 52.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 48.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 59.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 10.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 53.8MB/s \n",
            "\u001b[?25h  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oauth2client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.9 has requirement dill>=0.3.1, but you'll have dill 0.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n",
            "\u001b[31mERROR: pandas-gbq 0.11.0 has requirement google-cloud-bigquery>=1.9.0, but you'll have google-cloud-bigquery 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-translate 1.5.0 has requirement google-cloud-core<2.0dev,>=1.0.0, but you'll have google-cloud-core 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-storage 1.16.2 has requirement google-cloud-core<2.0dev,>=1.0.0, but you'll have google-cloud-core 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-datastore 1.7.4 has requirement google-cloud-core<2.0dev,>=0.29.0, but you'll have google-cloud-core 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-bigtable 1.0.0 has requirement google-cloud-core<2.0dev,>=1.0.0, but you'll have google-cloud-core 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "174uLTmLop2T",
        "colab_type": "text"
      },
      "source": [
        "<h3> Setting google env variables </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXiNj7u5ot1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "PROJECT = \"datascience-projects\" # REPLACE WITH YOUR PROJECT ID\n",
        "BUCKET = \"mm_dataflow_bucket\" # REPLACE WITH YOUR BUCKET NAME\n",
        "REGION = \"us-central1\" # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
        "\n",
        "# Do not change these\n",
        "os.environ[\"PROJECT\"] = PROJECT\n",
        "os.environ[\"BUCKET\"] = BUCKET\n",
        "os.environ[\"REGION\"] = REGION\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJnCvsO_pXM4",
        "colab_type": "code",
        "outputId": "d1d2fd61-4bff-4884-99cb-64625fbb84b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%bash\n",
        "gcloud config set project $PROJECT\n",
        "gcloud config set compute/region $REGION"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "Updated property [compute/region].\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c74-8qekOZF6",
        "colab_type": "text"
      },
      "source": [
        "<h3> Starting. Importing packages </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2Mb92e2OVeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.io import ReadFromText\n",
        "from apache_beam.io import WriteToText\n",
        "from apache_beam.metrics import Metrics\n",
        "from apache_beam.metrics.metric import MetricsFilter\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.options.pipeline_options import SetupOptions\n",
        "\n",
        "from itertools import groupby"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAE_a4iwPm8W",
        "colab_type": "text"
      },
      "source": [
        "<h3> Creating directory to hold data </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqn0eRr7OJx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjGNq_s-Ptm4",
        "colab_type": "code",
        "outputId": "571c001a-dd4f-4347-f65f-d244e74d705f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  data\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq4llbUMP1Kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing data into colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNR0IHL1Q5QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv dept-data.txt data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8JU7PwCGwWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls data\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVJU7KhmWn9",
        "colab_type": "text"
      },
      "source": [
        "<h3> Google Authentication </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92DyxfJhmaeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOGwgNi_rbe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from apache_beam.io.gcp.internal.clients import bigquery\n",
        "table_schema = 'source:STRING, quote:STRING'\n",
        "table_spec = bigquery.TableReference(\n",
        "    projectId=PROJECT,\n",
        "    datasetId='gcp_edgar',\n",
        "    tableId='test_edgar_data')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRCffYk0VA6c",
        "colab_type": "code",
        "outputId": "085e91eb-fad5-416b-eefc-2a336e25c939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "\n",
        "p2 = beam.Pipeline()\n",
        "test_buckt = 'gs://mm_dataflow_bucket/'\n",
        "lines = (\n",
        "     p2\n",
        "     | beam.Create([\n",
        "            {'source': 'Mahatma Gandhi', 'quote': 'My life is my message.'},\n",
        "            {'source': 'Yoda', 'quote': \"Do, or do not. There is no 'try'.\"},\n",
        "        ])\n",
        "     #| 'Filter perennials' >> beam.Filter(\n",
        "     #     lambda row: len(row.split(',')) > 3)\n",
        "     #| 'sending to putput' >> beam.Map(print)\n",
        "     #| beam.io.WriteToText('{}{}'.format(test_buckt, 'cutCreate1'))\n",
        "     |beam.io.WriteToBigQuery(\n",
        "        table_spec,\n",
        "        schema=table_schema,\n",
        "        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
        "        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED)\n",
        "\n",
        ")\n",
        "p2.run()\n",
        "# visualize output\n",
        "#!({'head -n 20 data/cutCreate1-00000-of-00001'})\n",
        "\n",
        "# check tis link fo rwriting to gcs https://colab.research.google.com/notebooks/io.ipynb#scrollTo=0ENMqxq25szn\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.local/lib/python3.6/site-packages/apache_beam/io/gcp/bigquery.py:1145: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
            "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
            "WARNING:root:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.RunnerResult at 0x7f01e10c4ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86G9mdxqfyOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d77LxRXtQ5f",
        "colab_type": "text"
      },
      "source": [
        "<h3> Edgar MasterIDX URL generation Pipeline </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s3IO_V5tT2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quarters = ['QTR1', 'QTR2', 'QTR3', 'QTR4']\n",
        "full_dir = \"https://www.sec.gov/Archives/edgar/full-index/{year}/{QUARTER}/\"\n",
        "def get_edgar_urls(years:list) :\n",
        "    print('fetching master.idx for year {}'.format(years))\n",
        "    idx_directories = [full_dir.format(year=year, QUARTER=qtr) for year in years for qtr in quarters]\n",
        "    return ['{}'.format(edgar_dir) for edgar_dir in idx_directories]\n",
        "output_bucket =  \"gs://mm_dataflow_bucket/outputs\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTtpHj7VwSTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "import shutil\n",
        "import requests\n",
        "import sys\n",
        "from pprint import pprint\n",
        "quarters = ['QTR1', 'QTR2', 'QTR3', 'QTR4']\n",
        "full_dir = \"https://www.sec.gov/Archives/edgar/full-index/{year}/{QUARTER}/\"\n",
        "\n",
        "\n",
        "# Using Beautiful soup\n",
        "import re, requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def processUrl(url):\n",
        "  if 'master.idx' in url:\n",
        "    return url\n",
        "\n",
        "def crawl(base_page):\n",
        "  req=requests.get(base_page)\n",
        "  good_ones = []\n",
        "  if req.status_code==200:\n",
        "      html=BeautifulSoup(req.text,'html.parser')\n",
        "      pages=html.find_all('a')\n",
        "      for page in pages:\n",
        "          url=page.get('href')\n",
        "          res = processUrl(url)\n",
        "          if res:\n",
        "            full_url = '{}{}'.format(base_page, res)\n",
        "            print('Appending..:{}'.format(full_url))\n",
        "            good_ones.append(full_url)\n",
        "      return good_ones\n",
        "\n",
        "def generate_master_urls(all_url):\n",
        "    res = map(lambda u: crawl(u), all_url)\n",
        "    pprint(res)\n",
        "    from itertools import chain\n",
        "    unpacked = chain(*res)\n",
        "    return list(unpacked)\n",
        "\n",
        "def generate_edgar_urls_for_year(year):\n",
        "    test_urls = ['https://www.sec.gov/Archives/edgar/full-index/{}/QTR1/',\n",
        "             'https://www.sec.gov/Archives/edgar/full-index/{}/QTR2/',\n",
        "             'https://www.sec.gov/Archives/edgar/full-index/{}/QTR3/',\n",
        "             'https://www.sec.gov/Archives/edgar/full-index/{}/QTR4/']\n",
        "    urls = map(lambda b_url: b_url.format(year), test_urls)\n",
        "    return generate_master_urls(urls)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQAyKp7Ox8kR",
        "colab_type": "code",
        "outputId": "572896c2-f371-4e27-b5cc-89cb7e7f8239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from past.builtins import unicode\n",
        "class FileExtractingDoFn(beam.DoFn):\n",
        "  \"\"\"Parse each line of input text into words.\"\"\"\n",
        "\n",
        "  def read_file(self, url):\n",
        "    with requests.get(url, stream=True) as r:\n",
        "      r.raise_for_status()\n",
        "      lines = []\n",
        "      print('Writing to:{}'.format(local_filename))\n",
        "      with open(local_filename, 'wb') as f:\n",
        "          for chunk in r.iter_content(chunk_size=8192):\n",
        "              if chunk: # filter out keep-alive new chunks\n",
        "                  f.write(chunk)\n",
        "\n",
        "  def crawl(self, base_page):\n",
        "    req=requests.get(base_page)\n",
        "    good_ones = []\n",
        "    if req.status_code==200:\n",
        "        html=BeautifulSoup(req.text,'html.parser')\n",
        "        pages=html.find_all('a')\n",
        "        for page in pages:\n",
        "            url=page.get('href')\n",
        "            res = processUrl(url)\n",
        "            if res:\n",
        "              full_url = '{}{}'.format(base_page, res)\n",
        "              print('Appending..:{}'.format(full_url))\n",
        "              good_ones.append(full_url)\n",
        "        return good_ones\n",
        "  def processUrl(self, url):\n",
        "    if 'master.idx' in url:\n",
        "      return url\n",
        "\n",
        "  def __init__(self):\n",
        "     # TODO(BEAM-6158): Revert the workaround once we can pickle super() on py3.\n",
        "    # super(WordExtractingDoFn, self).__init__()\n",
        "    beam.DoFn.__init__(self)\n",
        "  \n",
        "  def process(self, element):\n",
        "    \"\"\"Returns an iterator over the words of this element.\n",
        "    The element is a line of text.  If the line is blank, note that, too.\n",
        "    Args:\n",
        "      element: the element being processed\n",
        "    Returns:\n",
        "      The processed element.\n",
        "    \"\"\"\n",
        "    print('Processing {}'.format(element))\n",
        "    return self.crawl(element)\n",
        "\n",
        "p3 = beam.Pipeline()\n",
        "test_buckt = 'gs://mm_dataflow_bucket/'\n",
        "lines = (\n",
        "     p3\n",
        "     | 'generate edgar url' >>beam.Create(generate_edgar_urls_for_year('2019'))\n",
        "     \n",
        "     | 'extract master idx files' >> (beam.ParDo(FileExtractingDoFn())\n",
        "                                          .with_output_types(unicode)) \n",
        "     | 'sending to putput' >> beam.Map(print)\n",
        "     #beam.io.WriteToText('{}{}'.format('data/', 'cutCreate1'))\n",
        ")\n",
        "p3.run()\n",
        "# visualize output\n",
        "#!({'head -n 20 data/cutCreate1-00000-of-00001'})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c54652f0e2e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m      | 'extract master idx files' >> (beam.ParDo(FileExtractingDoFn())\n\u001b[1;32m     56\u001b[0m                                           .with_output_types(unicode)) \n\u001b[0;32m---> 57\u001b[0;31m      \u001b[0;34m|\u001b[0m \u001b[0;34m'sending to putput'\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m      \u001b[0;31m#beam.io.WriteToText('{}{}'.format('data/', 'cutCreate1'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_edgar_urls_for_year' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-yoa7ur29BO",
        "colab_type": "text"
      },
      "source": [
        "<h2> Test Pipeline that reads and parse Remote Filings remotely  </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zkQp0eczthS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from apache_beam.io import WriteToText\n",
        "from apache_beam.io.textio import ReadAllFromText\n",
        "import urllib\n",
        "from collections import defaultdict\n",
        "from datetime import date, datetime\n",
        "from itertools import groupby\n",
        "p4 = beam.Pipeline()\n",
        "test_bucket = 'gs://mm_dataflow_bucket/'\n",
        "form_type = '13F-HR'\n",
        "filename = '{}_{}'.format(form_type, datetime.now().strftime('%Y$m%d-%H%M'))\n",
        "\n",
        "\n",
        "class ReadRemote(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    print('REadRemote processing///{}'.format(element))\n",
        "    data = urllib.request.urlopen(element) # it's a file like object and works just like a file\n",
        "    return [line for line in data]\n",
        "\n",
        "class ParseForm13F(beam.DoFn):\n",
        "\n",
        "  def open_url_content(self, file_path):\n",
        "    import requests\n",
        "    print('Attepmting to open:{}'.format(file_path))\n",
        "    return requests.get(file_path)\n",
        "\n",
        "  def get_cusips(self, content):\n",
        "    data = content.text\n",
        "    data = data.replace('\\n', '')\n",
        "    subset = data[data.rfind('<XML>') + 5: data.rfind(\"</XML>\")]\n",
        "    from xml.etree import ElementTree\n",
        "    tree = ElementTree.ElementTree(ElementTree.fromstring(subset))\n",
        "    root = tree.getroot()\n",
        "    all_dt =  [child.text for infoTable in root.getchildren() for child in infoTable.getchildren()\n",
        "            if 'cusip' in child.tag]\n",
        "    return all_dt\n",
        "\n",
        "  def _group_data(self, lst):\n",
        "    all_dict = defaultdict(list)\n",
        "    if lst:\n",
        "      print('Attempting to group..')\n",
        "      data = sorted(lst, key=lambda x: x)\n",
        "      for k, g in groupby(data, lambda x: x):\n",
        "        grp = len(list(g))\n",
        "        if grp > 1:\n",
        "          print('{} has {}'.format(k, grp))\n",
        "        all_dict[k].append(grp)\n",
        "      \n",
        "  def process(self, element):\n",
        "    try:\n",
        "      file_content = self.open_url_content(element)\n",
        "      all_cusips = self.get_cusips(file_content)\n",
        "      #self._group_data(all_cusips)\n",
        "      #print('Found:{} in Processing {}'.format(len(all_cusips), element))\n",
        "      return all_cusips\n",
        "    except Exception as e:\n",
        "      print('could not fetch data from {}:{}'.format(element, str(e)))\n",
        "      return []\n",
        "\n",
        "import requests\n",
        "def format_string(input_str):\n",
        "  return str(input_str.replace(\"b'\", \"\").replace(\"'\", \"\")).strip()\n",
        "\n",
        "def cusip_to_ticker(cusip):\n",
        "  try:\n",
        "    #print('Attempting to get ticker for {}'.format(cusip))\n",
        "    cusip_url = \"https://us-central1-datascience-projects.cloudfunctions.net/cusip2ticker/{fullCusip}\".format(fullCusip=cusip)\n",
        "    #print('Opening:{}'.format(cusip_url))\n",
        "    req=requests.get(cusip_url).json()\n",
        "    ticker =  req['ticker']\n",
        "    return format_string(ticker)\n",
        "  except Exception as e:\n",
        "    print('Unable to retrieve ticker for {}'.format(cusip))\n",
        "    return ''\n",
        "\n",
        "## BIG QUERY SCHEMA\n",
        "from apache_beam.io.gcp.internal.clients import bigquery\n",
        "edgar_table_schema = 'COB:STRING, CUSIP:STRING, COUNT:INTEGER, TICKER:STRING'\n",
        "edgar_table_spec = bigquery.TableReference(\n",
        "    projectId=PROJECT,\n",
        "    datasetId='gcp_edgar',\n",
        "    tableId='form_13hf_data')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R38BJSiASQqe",
        "colab_type": "code",
        "outputId": "67bfe5dd-46c2-42c2-ae3e-b2736db96d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "lines = (\n",
        "     p4\n",
        "     #| 'generate master url' >>beam.Create(['https://www.sec.gov/Archives/edgar/full-index/2019/QTR1/master.idx'])\n",
        "     | 'Sampling Data' >> beam.Create(['https://www.sec.gov/Archives/edgar/full-index/2019/QTR1/master.idx',\n",
        "                    #'https://www.sec.gov/Archives/edgar/full-index/2019/QTR2/master.idx'\n",
        "                    ])\n",
        "     | 'readFromText' >> beam.ParDo(ReadRemote())\n",
        "     | 'map to Str'   >> beam.Map(lambda line:str(line))\n",
        "     | 'Filter only form 13HF' >> beam.Filter(lambda row: len(row.split('|')) > 4 and form_type in row.split('|')[2])\n",
        "     | 'Generating Proper file path' >> beam.Map(lambda row: '{}/{}'.format('https://www.sec.gov/Archives', row.split('|')[4]))\n",
        "     | 'replacing eol' >> beam.Map(lambda p: p[0:p.find('\\\\n')])\n",
        "     | 'sampling lines' >> beam.transforms.combiners.Sample.FixedSizeGlobally(10)\n",
        "     | 'flat Mapping' >> beam.Map(lambda elements: elements[0])\n",
        "     | 'parsing edgar filing' >> beam.ParDo(ParseForm13F())\n",
        "     | 'Combining similar' >> beam.combiners.Count.PerElement()\n",
        "     | 'Groupring' >> beam.MapTuple(lambda word, count: (word, count))\n",
        "     #| 'sampling again' >> beam.transforms.combiners.Sample.FixedSizeGlobally(20)\n",
        "     | 'Adding Cusip' >> beam.MapTuple(lambda word, count: (word, cusip_to_ticker(word), count))\n",
        "     #| 'Filtering' >> beam.Filter(lambda tpl: tpl[1] > 300)\n",
        "     | 'Creating BigQuery Data' >> beam.MapTuple(lambda word, ticker, count: dict(COB=date.today().strftime('%Y-%m-%d'), CUSIP=word, TICKER=ticker,COUNT=count))\n",
        "     | 'Write to BigQuery' >> beam.io.WriteToBigQuery(\n",
        "                                            edgar_table_spec,\n",
        "                                            schema=edgar_table_schema,\n",
        "                                            write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
        "                                            create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED)\n",
        "     #| 'sending to out' >> beam.Map(print)\n",
        "     #| beam.io.WriteToText('{}{}'.format(test_bucket, filename))\n",
        "     #|  beam.io.WriteToText('cutCreate1-00000-of-00001')\n",
        ")\n",
        "p4.run()\n",
        "# visualize output\n",
        "#!({'head -n 20 cutCreate1-00000-of-00001'})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.local/lib/python3.6/site-packages/apache_beam/io/gcp/bigquery.py:1145: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
            "  experiments = p.options.view_as(DebugOptions).experiments or []\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REadRemote processing///https://www.sec.gov/Archives/edgar/full-index/2019/QTR1/master.idx\n",
            "Attepmting to open:https://www.sec.gov/Archives/edgar/data/1632512/0001062993-19-000951.txt\n",
            "Unable to retrieve ticker for 02752P100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Unable to retrieve ticker for 89376V100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.RunnerResult at 0x7f01d4c1d6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ATv3ybfxJHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!({'head -n 20 data/cutCreate1-00000-of-00001-00000-of-00001'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fqEUAba03AY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6_HcnZeS7Cs",
        "colab_type": "text"
      },
      "source": [
        "<h3>FEtching Ticker from Cusip </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBXob6wwS2YS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZgVnig0V7WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cusips = ['00401C108',\n",
        "         '00404A109',\n",
        "         '004225108',\n",
        "         '004239109',\n",
        "        '00434H108',\n",
        "         'G1151C101',\n",
        "        '00081T108']\n",
        "\n",
        "for c in cusips:\n",
        "  ticker = cusip_to_ticker(c)\n",
        "  print('CUSIP:{}|TICKER:{}'.format(c, ticker))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wsHhmhUbzIf",
        "colab_type": "text"
      },
      "source": [
        "<h3> Other data to join in </h3>\n",
        "\n",
        "\n",
        "1.   Price Targets:GET /stock/{symbol}/price-target (500 messages per symbol)\n",
        "2.   Estimates:https://iexcloud.io/docs/api/#estimates (10000 per symbols)\n",
        "3.   Key Stats:GET /stock/{symbol}/stats/{stat?} day200MovingAvg, peRatio, beta,ytdChangePercent\n",
        "4. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJLLShdcvBer",
        "colab_type": "text"
      },
      "source": [
        "<h3>Price Targets </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3p_1Eg4S2ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "def get_iexapi_keys():\n",
        "  with open('gdrive/My Drive/passwords/iexapi.keys') as f:\n",
        "    return f.readlines()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-awAVnVWS2ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "def get_price_targets(symbol):\n",
        "  price_targets_url = 'https://cloud.iexapis.com/stable/stock/{symbol}/price-target?token={token}'.format(symbol=symbol, token=get_iexapi_keys())\n",
        "  return requests.get(price_targets_url).json()\n",
        "\n",
        "def get_analysts_recommendation_trends(symbol):\n",
        "  price_targets_url = 'https://cloud.iexapis.com/stable/stock/{symbol}/recommendation-trends?token={token}'.format(symbol=symbol, token=get_iexapi_keys())\n",
        "  return requests.get(price_targets_url).json()\n",
        "\n",
        "get_analysts_recommendation('VZ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HpZcMCKw3l9",
        "colab_type": "text"
      },
      "source": [
        "<h3> Estimates </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq9oNMDH2SMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_estimates(symbol):\n",
        "  price_targets_url = 'https://cloud.iexapis.com/stable/stock/{symbol}/estimates?token={token}'.format(symbol=symbol, token=get_iexapi_keys())\n",
        "  return requests.get(price_targets_url).json()\n",
        "\n",
        "get_estimates('JNJ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LJOb73j3caf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from apache_beam.transforms.combiners import Sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tkjvJIO2Rk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test read remote file\n",
        "def open_url_content(file_path):\n",
        "  import requests\n",
        "  return requests.get(file_path)\n",
        "\n",
        "def get_cusips(file_content):\n",
        "  data = content.text\n",
        "  data = data.replace('\\n', '')\n",
        "  subset = data[data.rfind('<XML>') + 5: data.rfind(\"</XML>\")]\n",
        "  from xml.etree import ElementTree\n",
        "  tree = ElementTree.ElementTree(ElementTree.fromstring(subset))\n",
        "  root = tree.getroot()\n",
        "  all_dt =  [child.text for infoTable in root.getchildren() for child in infoTable.getchildren()\n",
        "          if 'cusip' in child.tag]\n",
        "  return all_dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z23Ih4FISVfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sorting a pipeline in python\n",
        "p2 = beam.Pipeline()\n",
        "lines = (\n",
        "     p2\n",
        "     | beam.Create([('Test', 1), ('Another', 5), ('Third', 4)])\n",
        "     | 'Sorting values perennials' >> beam.Filter(\n",
        "          lambda row: len(row.split(',')) > 3)\n",
        "     | 'sending to putput' >> beam.Map(print)\n",
        "     #| beam.io.WriteToText('{}{}'.format(test_buckt, 'cutCreate1'))\n",
        ")\n",
        "p2.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MvlrFeHW6G2",
        "colab_type": "text"
      },
      "source": [
        "<h3> Testing a PIpelien for retrieving shares </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGTxC2XSW_Dc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "1849bf2f-2526-4802-e9cc-16c2dfce4ce1"
      },
      "source": [
        "!pip install pandas-datareader"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (0.25.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (2.21.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (1.11.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (1.17.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.19.2->pandas-datareader) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKu-xLCtXbiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pandas.tseries.offsets import BDay\n",
        "import pandas_datareader.data as dr\n",
        "import numpy as np\n",
        "from datetime import datetime, date\n",
        "import requests\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0YFMGJye4IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_shares_dataframe():\n",
        "  all_shares = requests.get('https://k1k1xtrm88.execute-api.us-west-2.amazonaws.com/test/query-shares').json()\n",
        "  ds = [d for d in all_shares if d['QTY'] > 1]\n",
        "  return pd.DataFrame.from_dict(ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6taKK6DXft8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_latest_price_yahoo(symbol, cob_date):\n",
        "  try:#\n",
        "    print('--latest price for{}'.format(symbol))\n",
        "    start_date = cob_date - BDay(1)\n",
        "    dfy = dr.get_data_yahoo(symbol, start_date, start_date)[['Adj Close']]\n",
        "    dft = dr.get_data_yahoo(symbol, cob_date, cob_date)[['Adj Close']]\n",
        "    dfy['symbol'] = symbol\n",
        "    dft['symbol'] = symbol\n",
        "\n",
        "    merged = pd.merge(dft, dfy,on='symbol', suffixes=('_t', '_y'),)\n",
        "    merged['diff'] = merged['Adj Close_t'] - merged['Adj Close_y']\n",
        "    return merged\n",
        "                                                           \n",
        "    \n",
        "  except Exception as e :\n",
        "    print('Unable to find data for {}'.format(symbol))\n",
        "    return pd.DataFrame.from_dict({'symbol': [symbol], 'Adj Close_t': [0], 'Adj Close_y':[0], 'diff':[0]})\n",
        "\n",
        "def get_prices(symbols):\n",
        "  prices_dfs = (get_latest_price_yahoo(symbol, date.today()) for symbol in symbols)\n",
        "  all_data = pd.concat(prices_dfs)\n",
        "  return all_data\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecAqH5OFXpqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1f3ee23-c0ec-4346-84df-776863470849"
      },
      "source": [
        "all_shares_df = get_all_shares_dataframe()\n",
        "symbols = all_shares_df['TICKER'].values[0:20]\n",
        "prices_data = get_prices(symbols)\n",
        "pd.merge(all_shares_df, prices_data, left_on='TICKER', right_on='symbol')\n",
        "\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--latest price forAAPL\n",
            "--latest price forACBFF\n",
            "Unable to find data for ACBFF\n",
            "--latest price forADAC \n",
            "Unable to find data for ADAC \n",
            "--latest price forAGEEF\n",
            "--latest price forAMBS\n",
            "--latest price forAMZN\n",
            "--latest price forAPTY\n",
            "--latest price forARSC\n",
            "--latest price forAZFL\n",
            "--latest price forBAC\n",
            "--latest price forBRK.B\n",
            "Unable to find data for BRK.B\n",
            "--latest price forBTCS\n",
            "--latest price forCRNT\n",
            "--latest price forDGP\n",
            "--latest price forENPH\n",
            "--latest price forHAON\n",
            "--latest price forHMNY\n",
            "--latest price forINDOY \n",
            "Unable to find data for INDOY \n",
            "--latest price forJNJ\n",
            "--latest price forLEMIF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TICKER</th>\n",
              "      <th>NAME</th>\n",
              "      <th>QTY</th>\n",
              "      <th>PRICE</th>\n",
              "      <th>Adj Close_t</th>\n",
              "      <th>Adj Close_y</th>\n",
              "      <th>diff</th>\n",
              "      <th>symbol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>Apple Inc</td>\n",
              "      <td>64</td>\n",
              "      <td>66.330000</td>\n",
              "      <td>318.730011</td>\n",
              "      <td>315.239990</td>\n",
              "      <td>3.490021</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ACBFF</td>\n",
              "      <td>Aurora Cannabis</td>\n",
              "      <td>200</td>\n",
              "      <td>6.280000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>ACBFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAC</td>\n",
              "      <td>ADAMA TECHNOLOGIES</td>\n",
              "      <td>62000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>ADAC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AGEEF</td>\n",
              "      <td>HALO LABS INC</td>\n",
              "      <td>4000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.242277</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.022277</td>\n",
              "      <td>AGEEF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AMBS</td>\n",
              "      <td>AMARANTUS BIOSCIENCE</td>\n",
              "      <td>4000</td>\n",
              "      <td>0.049037</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>AMBS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>8</td>\n",
              "      <td>1384.270000</td>\n",
              "      <td>1864.719971</td>\n",
              "      <td>1877.939941</td>\n",
              "      <td>-13.219971</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>APTY</td>\n",
              "      <td>APTSYSTEMINC</td>\n",
              "      <td>70000</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>APTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ARSC</td>\n",
              "      <td>AmericanSec Res</td>\n",
              "      <td>600</td>\n",
              "      <td>1.248250</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>-0.009900</td>\n",
              "      <td>ARSC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AZFL</td>\n",
              "      <td>AMAZONAS FLORESTAL</td>\n",
              "      <td>999999</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>AZFL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BAC</td>\n",
              "      <td>Bank of america</td>\n",
              "      <td>100</td>\n",
              "      <td>30.940000</td>\n",
              "      <td>34.709999</td>\n",
              "      <td>34.720001</td>\n",
              "      <td>-0.010002</td>\n",
              "      <td>BAC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>BRK.B</td>\n",
              "      <td>BERKSHIRE HATAWAY</td>\n",
              "      <td>45</td>\n",
              "      <td>64.108000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>BRK.B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>BTCS</td>\n",
              "      <td>BT CS</td>\n",
              "      <td>278</td>\n",
              "      <td>0.117000</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>BTCS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CRNT</td>\n",
              "      <td>CERAGON NETWORKS</td>\n",
              "      <td>1000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>2.240000</td>\n",
              "      <td>-0.040000</td>\n",
              "      <td>CRNT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>DGP</td>\n",
              "      <td>DB Gold Double LOng</td>\n",
              "      <td>50</td>\n",
              "      <td>27.680000</td>\n",
              "      <td>32.132301</td>\n",
              "      <td>31.760000</td>\n",
              "      <td>0.372301</td>\n",
              "      <td>DGP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ENPH</td>\n",
              "      <td>ENphase Energy</td>\n",
              "      <td>200</td>\n",
              "      <td>7.014000</td>\n",
              "      <td>31.500000</td>\n",
              "      <td>30.830000</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>ENPH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>HAON</td>\n",
              "      <td>Halitron Inc</td>\n",
              "      <td>999999</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>HAON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>HMNY</td>\n",
              "      <td>HELIOS  MATHESON</td>\n",
              "      <td>4</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.002450</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>HMNY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>INDOY</td>\n",
              "      <td>INDOY</td>\n",
              "      <td>150</td>\n",
              "      <td>18.080000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>INDOY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>JNJ</td>\n",
              "      <td>JohnsonJohnson</td>\n",
              "      <td>40</td>\n",
              "      <td>129.123750</td>\n",
              "      <td>149.169998</td>\n",
              "      <td>148.199997</td>\n",
              "      <td>0.970001</td>\n",
              "      <td>JNJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LEMIF</td>\n",
              "      <td>LEADING EDGE MAT</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.129700</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>-0.005000</td>\n",
              "      <td>LEMIF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    TICKER                  NAME     QTY  ...  Adj Close_y       diff  symbol\n",
              "0     AAPL             Apple Inc      64  ...   315.239990   3.490021    AAPL\n",
              "1    ACBFF       Aurora Cannabis     200  ...     0.000000   0.000000   ACBFF\n",
              "2    ADAC     ADAMA TECHNOLOGIES   62000  ...     0.000000   0.000000   ADAC \n",
              "3    AGEEF         HALO LABS INC    4000  ...     0.220000   0.022277   AGEEF\n",
              "4     AMBS  AMARANTUS BIOSCIENCE    4000  ...     0.012500   0.002400    AMBS\n",
              "5     AMZN                Amazon       8  ...  1877.939941 -13.219971    AMZN\n",
              "6     APTY          APTSYSTEMINC   70000  ...     0.000250   0.000050    APTY\n",
              "7     ARSC       AmericanSec Res     600  ...     0.010000  -0.009900    ARSC\n",
              "8     AZFL    AMAZONAS FLORESTAL  999999  ...     0.000100   0.000000    AZFL\n",
              "9      BAC       Bank of america     100  ...    34.720001  -0.010002     BAC\n",
              "10   BRK.B     BERKSHIRE HATAWAY      45  ...     0.000000   0.000000   BRK.B\n",
              "11    BTCS                 BT CS     278  ...     0.060000  -0.002500    BTCS\n",
              "12    CRNT      CERAGON NETWORKS    1000  ...     2.240000  -0.040000    CRNT\n",
              "13     DGP   DB Gold Double LOng      50  ...    31.760000   0.372301     DGP\n",
              "14    ENPH        ENphase Energy     200  ...    30.830000   0.670000    ENPH\n",
              "15    HAON          Halitron Inc  999999  ...     0.000100   0.000000    HAON\n",
              "16    HMNY      HELIOS  MATHESON       4  ...     0.002300   0.000150    HMNY\n",
              "17  INDOY                 INDOY      150  ...     0.000000   0.000000  INDOY \n",
              "18     JNJ        JohnsonJohnson      40  ...   148.199997   0.970001     JNJ\n",
              "19   LEMIF      LEADING EDGE MAT    2000  ...     0.080000  -0.005000   LEMIF\n",
              "\n",
              "[20 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS1WZVbgXuwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "88c269d3-1611-4875-f0de-950c79406d1a"
      },
      "source": [
        "res.diff(axis=1, periods=-1)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-01-15</th>\n",
              "      <td>1.159988</td>\n",
              "      <td>-0.159988</td>\n",
              "      <td>-0.610001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-16</th>\n",
              "      <td>2.639999</td>\n",
              "      <td>-1.220001</td>\n",
              "      <td>-0.779999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                High       Low      Open  Close  Volume  Adj Close\n",
              "Date                                                              \n",
              "2020-01-15  1.159988 -0.159988 -0.610001    0.0     NaN        NaN\n",
              "2020-01-16  2.639999 -1.220001 -0.779999    0.0     NaN        NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwkB-bQVa7cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}